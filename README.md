# SIDS DETECTOR
<details>
<summary>ğŸ“– Table of Contents</summary>
- [ğŸ¯ Project Goal](#-project-goal)  
- [â“ Problem Definition](#-problem-definition)  
- [ğŸ’¡ Proposed Solution](#-proposed-solution)  
- [ğŸ”„ System Workflow](#-system-workflow)  
- [ğŸ§  Computer Vision Model Pipeline](#-computer-vision-model-pipeline)  
  - [ğŸ” YOLOv8 Face Detection](#-yolov8-face-detection-model)  
  - [ğŸƒ YOLOv8 Pose Estimation](#-yolov8-pose-estimation-model)  
  - [ğŸ› ï¸ Feature Engineering & Embedding](#-feature-engineering--embedding)  
  - [ğŸ“Š XGBoost Classifier](#-xgboost-classifier)  
- [ğŸ¥ Qualitative Results](#-qualitative-results)  
- [ğŸ“¦ Installation](#-installation)  
- [ğŸš€ Running the Project](#-running-the-project)  
- [ğŸ“ŠğŸ–¼ï¸ Output](#-output)
</details>

## ğŸ¯ Project goal
This project aims to develop a computer visionâ€“based **monitoring system** to track infants while they sleep and detect potentially dangerous positions that may increase **the risk of Sudden Infant Death Syndrome (SIDS)**.
## â“Problem definition
SIDS is strongly associated with situations in which a babyâ€™s airways become obstructed during sleep.The sleeping position plays a critical role:
- ğŸŸ¥ **Prone position** (lying face down) â€“ highest risk of suffocation. 
- ğŸŸ§ **Side positions** (lying on the left or right side) â€“ increased risk if the babyâ€™s mouth and nose are pressed against the mattress, pillow, or blanket.
- ğŸŸ© **Supine position** (on the back, face up) â†’ safest position, airways unobstructed.

**In this project, we define:**
- **Baby Safe**: infant is in a safe sleeping position.
- **Baby in Danger**: infant is in a potentially risky position.

## ğŸ’¡ Proposed solution
We aim to create a smart baby monitor positioned above the crib, continuously analyzing video frames in real time.

At this stage of development, our focus is on the computer vision model, responsible for:
- Analyzing video frames in real time.
- Detecting the babyâ€™s body pose and face features.
- Classifying frames as "baby safe" or "baby in danger".

â¡ï¸ Future work will integrate this into a real monitoring device, connected to an alert system to notify parents when a dangerous posture is detected.

## ğŸ”„ System Workflow
Overall, the smart baby monitor works like this:
```mermaid
flowchart TD
  A[Camera above crib] --> B[Frame acquisition]
  B --> C[Preprocessing with CLAHE]
  C --> D[Computer Vision Model]
  D --> G{Inference}
  G -->|Baby in danger| H[âš ï¸Alert]
  G -->|Baby safe| I[âœ…No action]
```

## ğŸ§  Computer vision model pipeline
During this stage, we focused on the computer vision model, whose processing pipeline includes:
```mermaid
flowchart TD
    A[Frame] --> |YOLOv8 face detection| B[Face features]
    A--> |YOLOv8 pose estimation| C[Pose features]
    B--> |Feature elaboration:\n angles and distances evaluation, normalization| D
    C--> |Feature elaboration:\n angles and distances evaluation, normalization| D
    D[Embedding with face and pose information]
    D-->|Processing with MLP| E[ Learned embedding ]
    E--> G[XGBoost classifier]
    G--> H{Inference}
    H -->|Baby in danger| I( )
    H -->|Baby safe| K( )
    
    
```

### ğŸ” YOLOv8 face detection model
The first element of our pipeline is the YOLOv8 face detection model
It was fine-tuned with [this dataset](https://app.roboflow.com/sids-project-3gvel/dataset_v3-hn7xa/1) after careful data augmentation.

### ğŸƒ YOLOv8 pose estimation model
The second element of our pipeline is the YOLOv8 pose estimation model.
It was fine-tuned with [this dataset](https://universe.roboflow.com/sids-project-3gvel/pose_estimation-merged-gdksv/dataset/1m) after careful data augmentation.


### ğŸ› ï¸ Feature Engineering & Embedding
From YOLO outputs, we extract handcrafted features (86 total):
- **Face-related**: landmark presence, normalized positions, geometric relations (angles, aspect ratios, eye-to-mouth distances).
- **Pose-related**: normalized keypoints, distances between joints, torsion, and angles.

â¡ï¸ These features are passed through an MLP trained with Supervised Contrastive Loss, producing a 32-dimensional learned embedding.

### ğŸ“Š XGBoost classifier
- Multiple classifiers were tested with hyperparameter optimization, and the best one was selected to predict â€œbaby safeâ€ or â€œbaby in dangerâ€.
- XGBoost achieved the best balance of:
	- âœ… High recall (especially for â€œbaby in dangerâ€ cases).
	- âœ… Strong accuracy.
	- âœ… Low overfitting tendency.

| | **precision** | **recall** | **f1-score** | **support** |
| :--- | :---: | :---: | :---: | :---: |
| **baby_safe** | 0.96 | 0.94 | 0.95 | 423 |
| **baby_unsafe** | 0.94 | 0.96 | 0.95 | 409 |
| | | | | |
| **accuracy** | | | 0.95 | 832 |
| **macro avg** | 0.95 | 0.95 | 0.95 | 832 |
| **weighted avg**| 0.95 | 0.95 | 0.95 | 832 |

<img src="README_resources/confusion_matrix.png" width="40%">

## ğŸ¥ Qualitative results
![Demo](README_resources/classification_demo.gif)

Our model is frame-based. Future work may include inter-frame analysis to stabilize predictions, but this provides a solid foundation for further refinement.

The demo video was AI generated using VEO.

## ğŸ”§ Installation
In progress
## ğŸš€ Running the Project
In progress
## ğŸ–¼ï¸ Output
In progress

